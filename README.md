# Parameter-Efficient-Fine-Tuning_of_Phi-2_using_LoRA_under_8-Bit_Quantization
A memory-efficient fine-tuning pipeline for Microsoft's Phi-2 model, utilizing 8-bit quantization and Low-Rank Adaptation (LoRA) to enable training on consumer-grade GPUs.
